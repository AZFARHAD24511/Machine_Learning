# Machine_Learning
# ðŸ“Š Machine Learning Model Results and Performance Comparison

In this analysis, the following preprocessing steps were applied:
- Removed the "Label" column and company names,
- Extracted the first two digits from the SIC code,
- Kept the state name as a categorical feature,
- Used all available numerical features.

The data was split using a **time-based split** (based on year and quarter) into:
- **Training set**: 2009â€“2022  
- **Test set**: 2023â€“2025  

The models evaluated include:
- **Linear Regression**
- **Ridge Regression (Î±=1)**
- **Random Forest**
- **XGBoost** *(only if it ran efficiently)*

### ðŸ“‹ Model Performance Comparison

> **Note**: Higher RÂ² and lower RMSE, MAE, MAPE indicate better performance.

| Model                    | RMSE         | MAE          | MAPE      | RÂ²     | Training Time (sec) |
|--------------------------|--------------|--------------|-----------|--------|----------------------|
| Linear Regression        | 7.38Ã—10â¹     | 4.68Ã—10â¹     | ~46413%   | 0.40   | 0.40                 |
| Ridge Regression (Î±=1)   | 7.38Ã—10â¹     | 4.68Ã—10â¹     | ~46100%   | 0.40   | 0.13                 |
| Random Forest            | 2.78Ã—10â¹     | 3.31Ã—10â¸     | ~2113%    | 0.915  | 2.64                 |

---

### ðŸ“ Notes:

- The **very high MAPE values** are due to the presence of **zero or negative net income** in some records, which leads to extremely high percentage errors.
- **Random Forest**:
  - Achieved the **lowest error metrics** (RMSE, MAE),
  - Provided the **highest RÂ² score** on the test set (0.915),
  - Shows signs of **overfitting** (Training RÂ² â‰ˆ 0.988).
- **Linear and Ridge Regression**:
  - Lower prediction accuracy,
  - But **extremely fast training times**,
  - Similar RÂ² scores for training and test sets suggest **minimal overfitting**.

### ðŸ” Data Leakage Considerations:

- **No data leakage** was detected because a **temporal split** was used and no future data was leaked into the training set.

### ðŸ† Conclusion:

- **Best-performing model (accuracy-wise):** Random Forest â€” *lowest RMSE and MAE, highest RÂ²*  
- **Fastest models:** Linear and Ridge Regression â€” *very short training time*

> Although XGBoost was tested, it was excluded from the table due to long execution time in the given environment. Final conclusions are based on the models listed above.

---

### ðŸ“š References:

The results presented are based solely on the given dataset and independently computed metrics. No external sources were used for numerical benchmarks. Definitions of metrics and discussions on overfitting and data leakage are based on standard machine learning practices.
